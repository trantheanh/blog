---
title: "[ML – 10] Regularization – Overfitting and Underfitting"
date: 2016-12-12
layout: post
comments: true
mathjax: true
---

Chào các bạn, sau khi chúng ta cùng nhau học về một số mô hình cơ bản trong Machine Learning cũng như một số giải thuật hay được sử dụng thì hôm nay, ta sẽ dừng lại một chút để xem xét và giải quyết vấn đề chính hay gặp phải trong quá trình xây dựng và phát triển một mô hình ML. Cụ thể chúng ta sẽ đi tìm hiểu về vấn đề **Overfitting** và **Underfitting**.
Xem qua lại một chút các bước xây dựng mô hình để giải quyết một vấn đề bằng ML:
– Lựa chọn **feature**: xác định những input cơ bản để tiến hành thu thập dữ liệu là công việc đầu tiên khi làm việc với ML, chỉ khi ta biết được những feature nào nên được lựa chọn, khi đó quá trình thu thập dữ liệu mới có thể bắt đầu.
– Thu thập **data**: Càng nhiều dữ liệu ta càng dễ quan sát được tính hội tụ của chúng, kết quả học càng cao. Tuy nhiên bù lại là tốn hiệu năng cho việc duyệt qua tập dữ liệu (lớn), thời gian học lâu hơn.
– Xây dựng mô hình: Sau khi lựa chọn một mô hình phù hợp chẳng hạn Logistic Regression cho **Classification Problem**, hay Linear Regression cho **Regression Problem** ta xây dựng \\(h(x)\\), cost function \\(J(\theta)\\) và tối thiểu hóa cost function nhiều nhất có thể. Đến bước này chúng ta sẽ gặp vấn đề với **Overfitting** và **Underfitting**. Chúng là gì và cách giải quyết ra sao sẽ được đề cập trong phần tiếp theo.
– Validate và test: sau khi có hàm tiên đoán \\(h(x)\\) chúng ta sẽ thực hiện validate và kiểm thử với dữ liệu mới (Chi tiết sẽ được mô tả trong bài viết sau).

## 1. Overfitting & Underfitting:

Để hiểu về vấn đề này chúng ta sẽ cùng nhau xem xét ví dụ sau: 

<img src="/assets/content_images/ml10-01.png" alt = "" width = "70%">

Trong ví dụ này, tôi đang đề cập đến một Regression Problem, do đó y nhận giá trị liên tục. Nếu ứng dụng Linear Regression chúng ta sẽ thu được \\(h(x)\\) như sau: 

<img src="/assets/content_images/ml10-02.png" alt = "" width = "70%">

Hàm \\(h(x)\\) thu được ở trên có vẻ không được tốt, bản thân đối với dữ liệu training ta đã thấy được sai số rõ rệt chứ chưa nói tới việc thử trên dữ liệu mới – Trong trường hợp này vấn đề chúng ta gặp phải được gọi là **Underfitting**. Để phát triển lên mô hình tốt hơn, ta thử thêm vào một số thành phần đa thức, chẳng hạn đưa hàm số từ tuyến tính lên bậc 2. Có lẽ \\(h(x)\\) sẽ có dạng như sau: 

<img src="/assets/content_images/ml10-03.png" alt = "" width = "70%">

Mọi thứ có vẻ tốt hơn, tuy không **fit** với mọi dữ liệu nhưng nhìn qua hàm \\(h(x)\\) này đi theo đúng xu hướng của dữ liệu (nơi dữ liệu hội tụ hay pattern của chúng). Nhưng nếu như ta tiếp tục thêm các thành phần đa thức vào \\(h(x)\\), có thể giúp cho \\(h(x)\\) **fit** với mọi dữ liệu hay chí ít là phần lớn của chúng, tối thiểu được cost function về xấp xỉ 0, chẳng hạn: 

<img src="/assets/content_images/ml10-04.png" alt = "" width = "70%">

\\(h(x)\\) dường như đi qua mọi dữ liệu training, có nghĩa là cost function của ta gần xấp xỉ 0. Đúng ra khi cost function càng thấp, ta phải thu được \\(h(x)\\) tốt hơn, nhưng trong trường hợp này, rõ ràng \\(h(x)\\) không đi theo xu thế của dữ liệu mà chỉ đơn thuần **fit** được nhiều dữ liệu training hay nói cách khác khi ta đưa \\(h(x)\\) vào sử dụng, nó cũng không thể dự đoán tốt được. Trường hợp đơn giản nhất ở đây là khi bậc của \\(h(x)\\) cao hơn hoặc bằng số lượng dữ liệu training. Vấn đề này được gọi là **Overfitting**.
**Underfitting** là khi mô hình của ta quá đơn giản, không thể giảm thiểu được đáng kể cost function nên cũng không thể mô tả được xu hướng của dữ liệu (còn được gọi là **High Bias**). Ngược lại **Overfitting** lại là khi mô hình của ta quá phức tạp, tuy giảm thiểu được đáng kể, thậm chí toàn bộ sai số nhưng cũng không thể mô tả được xu hướng của dữ liệu (còn được gọi là **High Variance**).
Tương tự với Logistic Regression, nhưng vấn đề gặp phải không phải ở h(x) mà ở Decision Boundary:

<img src="/assets/content_images/ml10-05.png" alt = "" width = "90%">

## 2. How do we solve it ?

Trước tiên, chắc các bạn sẽ tự đặt câu hỏi rằng khi nào thì ta biết mô hình của mình đang bị **Underfitting** hay **Overfitting** trước khi nghĩ đến chuyện giải quyết chúng như thế nào. Tuy nhiên để xác định được chúng ta cần phải test và validate hơi phức tạp chút xíu, nên tôi sẽ đề cập trong bài tới nên hiện giờ chúng ta hãy xem giải quyết chúng thế nào đã!
– Với **Underfitting** thì chỉ đơn thuần là mô hình của ta quá đơn giản, nên ta cần thêm những thành phần đa thức để nó phức tạp hơn. Nên khi giá trị của cost function lớn ta sẽ đẩy bậc của hàm số lên. Dĩ nhiên đẩy lên cao quá ta sẽ gặp vấn đề về performance và Overfitting.
– Với **Overfitting** thì công việc lại ngược lại, do mô hình quá phức tạp nên ta cần giảm bậc của hàm số hay giảm số lượng feature. Việc giảm feature ngoài bỏ bớt những thành phần đa thức, ta còn có thể bỏ bớt những feature không cần thiết. Một cách khác là áp dụng **Regularization**!

## 3. Regularization:

Trong ví dụ về Linear Regression đã nói ở trên, ta có thể thấy rằng với bậc đa thức = 2 thì \\(h(x)\\) là mô hình tốt còn khi đẩy lên bậc 3, hay 4 thì \\(h(x)\\) sẽ gặp vấn đề với Overfitting. Vậy rõ ràng điều ta nên làm là bỏ đi các feature = x3, x4. Cost function của Linear Regression như sau: 

\\[ J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_{\theta}(x^{(i)}) - y^{(i)})^{2} \\]

Thay vì bỏ trực tiếp \\(x^3\\), \\(x^4\\), ta có thể thay đổi cost function để khi tối thiểu hoá sẽ thu được \\(\theta\\) của \\(x^3\\), \\(x^4\\) nhỏ, xấp xỉ = 0. Chẳng hạn:

\\[ J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_{\theta}(x^{(i)}) - y^{(i)})^{2} + 1000 \mathbf{\theta _{3}^{2}} + 1000 \mathbf{\theta _{4}^{2}}\\]

Khi ta thêm một lượng lớn \\(\theta_3\\), \\(\theta_4\\) sẽ dẫn đên việc muốn giảm giá trị của cost function đồng nghĩa với việc \\(\theta_3\\), \\(\theta_4\\) phải nhỏ, cụ thể là càng gần 0 càng tốt (do ta thêm vào \\(\theta^2\\) nên giá trị nhỏ nhất khi chúng = 0). Khi \\(\theta_3\\), \\(\theta_4\\) xấp xỉ 0 thì các feature \\(x^3\\), \\(x^4\\) càng ít ảnh hưởng tới \\(h(x)\\). Hay nói cách khác đây là một hình thức giảm bậc của đa thức mà không phải thay đổi số lượng feature.
Mặc dù vậy nhưng câu hỏi đặt ra là làm sao để biết thành phần đa thức nào cần bỏ, thành phần nào không ? Trên thực tế khi làm việc với các vấn đề của ML ta phải sử dụng số lượng feature không chỉ một hay một vài, thậm chí là nhiều hơn hàng trăm feature. Khi đó việc lựa chọn ra feature nào bỏ đi một cách trực quan như trên là không tưởng! Vì vậy thay vào đó, ta thêm một thành phần tương tự \\(\theta_2\\) để giảm sự ảnh hưởng của tất cả các feature đến \\(h(x)\\). Phần này được gọi là **weight decay** - một trong những kĩ thuật **Regularization**.

\\[ J(\theta) = \frac{1}{2m} [\sum_{i=1}^{m} (h_{\theta}(x^{(i)}) - y^{(i)})^{2} + \lambda \sum_{i=1}^{n} \theta _{i}^{2}] \\]

Tham số \\( \lambda \\) được dùng để thay đổi mức ảnh hưởng của toàn bộ feature. Trong quá trình validate và test ta sẽ phải lựa chọn \\( \lambda \\) sao cho mô hình không bị vướng vào vấn đề **Overfitting**. Tuy nhiên bên cạnh đó, nếu để \\( \lambda \\) quá lớn sẽ khiến cho mọi feature đều không còn ảnh hưởng đến \\(h(x)\\), nghĩa là cost funtion vẫn sẽ quá lớn. Để ý một chút nữa là nếu như ta thêm cả \\(\theta _0^2\\) thì điều này không ý nghĩa vì bản thân \\(x_0\\) không phải là feature mà chỉ = 1. Do đó trong phần Regularization ta chỉ có \\(1 ≤ i ≤ n\\) (\\(n\\) là số lượng feature), khi \\( \lambda \\) quá lớn, mô hình sẽ chỉ đơn thuần phụ thuộc vào \\(\theta _0\\) nên dù tránh được **Overfitting**, mô hình sẽ vướng phải **Underfitting**.
Khi ứng dụng Gradient Descent, bước giảm trên từng \\( \theta \\) sẽ như sau: 

$$
\begin{align*}

\theta _0
& := \theta _0 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_{\theta} (x^{(i)}) - y^{(i)}) x_0^{(i)}\\
\theta _j
& := \theta _j - \alpha [\frac{1}{m} \sum_{i=1}^{m} (h_{\theta} (x^{(i)}) -y^{(i)}) x_j^{(i)} + \frac{\lambda}{m} \theta _j]\\

& j = 1,2,3,...,n

\end{align*}
$$

Nếu như ta nhóm \\(\theta_j\\) lại với nhau sẽ có: 

\\[ \theta _j := \theta _j (1 - \alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum _{i=1} ^{m} (h _{\theta} (x ^{(i)}) - y ^{(i)}) x  _{j}^{(i)} \\]

Trong đó: \\((1 – \alpha \frac{\lambda}{m})\\) luôn \\(< 1\\) vì \\(\alpha ,\lambda,m > 0\\). Chính vì vậy thực tế ngoài việc giảm dốc, mỗi bước giảm các \\(\theta\\) còn giảm thêm phần Regularization khiến chúng nhỏ hơn, ít ảnh hưởng tới mô hình. Trên thực tế \\((1 – \alpha \frac{\lambda}{m})\\) thường nằm trong khoảng \\([0.95 : 0.99]\\)
Tương tự ta có Regularization cho Logistic Regression với 1 hay nhiều class: 
**Logistic Regression:**

\\[ J(\theta) - \frac{1}{m} [\sum_{i=1}^{m} y^{(i)} log( h_{\theta} (x^{(i)}) ) + (1-y^{(i)}) (1-log( h_{\theta} (x^{(i)}) )) ] + \frac{\lambda}{2m} \sum_{j = 1}^{n} \theta _j ^2 \\]

**Logistic Regression with multiclass**

\\[ h_{\theta} (x) \in R^{K} \\]
\\[ ( h_{\theta} (x) )_k = k^{th} \space output\\]

\\[ J(\theta) = - \frac{1}{m} [\sum_{i=1}^{m} \sum_{k=1}^{K} y_{k}^{(i)} log( h _{\theta} (x ^{(i)}) ) _k + ( 1 - y _{k} ^{(i)} ) (1 -log( h _{\theta} (x ^{(i)}) ) _k) ] + \frac{\lambda}{2m} \sum _{ℓ=1} ^{L-1} \sum _{i=1} ^{s _{ℓ}} \sum _{j = 1} ^{s _{ℓ+1}} (\theta _{ji} ^{ℓ}) ^{2} \\]

\\(L\\): Số lượng layer (Input, Hidden & Output Layer).\\
\\(S_ℓ\\): Số lượng neuron của layer ℓ

Trong bài viết tiếp theo, tôi sẽ nói về một số phương pháp để loại bỏ **Underfitting** và **Overfitting**, đồng thời tìm hiểu làm sao để validate và test. Cảm ơn các bạn đã theo dõi bài viết, hẹn gặp lại trong bài tiếp theo.