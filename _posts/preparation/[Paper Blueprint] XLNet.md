[Paper Blueprint] XLNet: Generalized Autoregressive Pretraining for Language Understanding

## 1. Autoregressive Language Model

### What is an Autoregressive Model?

An autoregressive (AR) model **predicts future behavior based on past behavior**.  It’s used for forecasting when there is some correlation between values  in a time series and the values that precede and succeed them. You *only* use past data to model the behavior, hence the name *auto*regressive (the Greek prefix *auto*– means “self.” ). The process is basically a [linear regression](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/regression-analysis/find-a-linear-regression-equation/#definition) of the data in the current series against one or more past values in the same series. 

## 2. Autoencoding Language Model

## 3. Transformer-XL (Transformer Extra Long)

https://medium.com/dair-ai/a-light-introduction-to-transformer-xl-be5737feb13

Paper: https://arxiv.org/abs/1901.02860



## 4. Others

Transformer-XL addressed problem:

* *context fragmentation*

* *cannot capture **longer-term dependency**

  https://medium.com/dair-ai/a-light-introduction-to-transformer-xl-be5737feb13



